## 集群

Redis Cluster 是 Redis 的集群实现，能够自动的将数据分片到每个节点上。

Redis Cluster 功能的特点：
- 所有节点相互连接
- 集群消息通信通过集群总线通信，集群总线端口为客户端端口+10000
- 节点与节点之间通过二进制协议通信
- 客户端和集群节点之间的通信通过文本协议进行
- 集群节点不会代理查询
- 数据按照 Slot 存储分布在多个 Redis 实例上

### Redis 集群的优势
- 能够在多个节点自动拆分数据集
- 当节点的子集遇到故障或无法与集群的其余部分通信时，集群可以继续工作
- Redis 集群不支持多数据库，只有数据库 0，因此不支持 ```select <database>``` 操作
- Redis 集群实现了非分布式 Redis 的所有单个 key 的命令，并且只要多个 key 的命令在同一个节点也支持多 key 操作(如 Set 数据类型的交集和并集操作)
- 高性能和可线性扩展，最多可以扩展到 1000 个节点；没有代理，使用异步复制并且不对值进行合并操作。
- 接受一定程度的写安全：系统尽量保留连接大多数主节点的客户端的所有请求；通常会有小窗口的已确认的写数据会丢失；当客户端连接的是少数主节点时(由于网络分区)，这种缺失会更大
- Redis 集群能够在大多数主节点可访问并至少有一个从节点的分区可用，另外 Reids 的副本迁移可以在主节点没有从节点的情况下从其他主节点迁移从节点
### Redis 集群端口
Redis 集群中的每个节点需要打开两个 TCP 端口：
- 用于为客户端提供服务的端口，如 6379
- 用于集群内部的端口(提供服务的端口值 + 10000)，如 16379

集群内部的端口用于集群总线，即使用二进制协议的节点到节点之间的通信信道；节点之间通过集群总线进行故障检测、配置更新、故障转移等。客户端不应尝试与集群总线端口通信而应始终与正常的 Redis 命令端口通信，但是服务器需要同时打开这两个端口，否则 Redis 集群节点将无法通信

用于为客户端提供服务的端口需要向所有客户端以及集群中的节点开放，而用于集群内部的端口需要向集群中所有的节点开放。

### 集群通信

### Redis 集群数据分片
Reids 集群没有使用一致性 hash 算法，而是使用哈希槽(hash slot)的概念来使数据分布在不同的节点。

Reids 集群的 key 空间分为 16384 个槽，集群中每个主节点处理这些槽的一个子集。当没有正在进行的集群重新配置时(即 hash 槽从一个节点移动到另外一个节点)，集群是稳定的，在集群稳定的情况下一个 hash 槽只只会有一个节点提供服务。

将 Redis key 映射到 hash 槽的算法：*HASH_SLOT = CRC16(KEY) mod 16384*

Redis 集群中有 16384 个哈希槽，采用将 key 的 CRC16 的值对 16384 取模确定该 key 属于哪个槽。Redis 的每个节点负责哈希槽的一个子集，例如如果 Reids 集群由 3 个节点，则：
- 节点 A 负责 0-5500 的哈希槽
- 节点 B 负责 5501-11000 的哈希槽
- 节点 C 负责 11001- 16838 的哈希槽

不同的 Node 负责不同的哈希槽使得增加节点和删除节点非常容易，在增加节点后只需要将其他节点的哈希槽移动到新节点即可，删除节点前将该节点上的哈希槽移动到其他节点即可。

将哈希槽从一个节点移动到另一个节点不需要停止操作，添加和删除节点或者更改节点所持有的哈希槽的百分比，所以不需要任何停机时间。

Redis 集群支持多个 key 的操作，只要一个命令执行中设计的所有 key 都属于同一个哈希槽。可以使用称为哈希标记(hash tag)的方法使得多个 key 属于同一个哈希槽。
### Redis 集群主从模型
为了在 master 节点的一个子集发生故障或者无法与大多数节点通信时保持可用性，Redis 集群使用主从模型，每个哈希槽都有 1~N 个副本(包括 master 自身)。例如一个集群有 A,B,C 三个节点，如果 B 节点故障则整个集群无法提供服务，因为5501-11000 的哈希槽再也不能提供服务；如果集群中为每个 master 节点添加了 slave，那么当 B 节点故障时 B1 节点就会被推举为新的 master 节点继续对外提供服务；如果 B 和 B1 都故障则集群无法继续提供服务。
### Redis 集群一致性保证
Redis 集群不能保证强一致性，也就是说在某些情况下集群有可能丢失客户端写入的数据。

Redis 集群不能保证强一致性的最主要原因是主从之间是采用异步复制的，这就有可能在主服务器崩溃之前还没有将数据同步到从服务器上，当从服务器被提升为主服务器之后数据将会永远丢失。

另外一个导致 Redis 集群丢失写操作的场景发生在网络分区中。例如有 3 个 master 节点和 3 个 slave 节点 A,B,C,A1,B1,C1 和一个客户单 Z1，当发生网络分区时，有可能 A,C,A1,B1,C1 为一个分区而 B,Z1 为一个分区，此时 Z1 会继续往 B 写入数据，一段时间后网络分区问题解决，如果网络分区持续的时间足够长导致 B1 被推举为 master 则网络分区解决后，Z1 向 B 写入的数据将会丢失。

### Redis 集群配置
Redis 的配置文件 redis.conf 可以配置集群的参数：
- ```cluster-enabled <yes/no>``` - 如果设置为 true，则该节点作为 Redis 集群的一个节点
- ```cluster-config-file <filename>``` - 该文件是集群节点发生变化时集群节点自动持久化集群配置的文件，以便能够在集群重启时重启读取；该文件列出了集群中的其他节点、节点的状态、持久变量等；该文件用户不可编辑
- ```cluster-node-timeout <milliseconds>``` - Redis 集群被视为不可用前不可用的最长时间；如果主节点的不可访问时间超过这个时间，则其从节点将进行故障转移
- ```cluster-slave-validity-factor <factor>``` - 如果设置为 0，则从节点无论主从之间连接断开的时间长短都会尝试进行故障转移；如果设置为正数，则计算节点的最大超时时间然后乘以 factor，如果节点是从节点，则在主从断开连接时间超过该值之前，从节点不会发起失效转移
- ```cluster-migration-barrier <count>``` - 与主节点保持连接的最小从节点数量，以便于一个从节点迁移到没有从节点的主节点
- ```cluster-require-full-coverage <yes/no>``` - 如果设置为 true(默认为 true)，则当一定比例的 key 空间不在任何一个节点上，节点将会停止接受写入；如果设置为 false，即使是只能处理部分子集，查询操作仍将支持
### 创建 Redis 集群
在创建集群之前需要创建 Redis 实例，配置集群相关参数并启动实例
```conf
port 7000
cluster-enabled yes
cluster-config-file nodes-7000.conf
cluster-node-timeout 5000
```
启动 Redis 实例：
```shell
../redis-server ./redis-7000.conf
```
创建 Redis 集群，Reids 5 提供了命令行工具，而 Redis 3 和 Redis 4 需要使用 redis-trib.rb 脚本创建集群
```shell
-- redis 5
redis-cli --cluster create 127.0.0.1:7000 127.0.0.1:7001 ... \
--cluster-replicas 1

-- redis 4
./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 ...
```
### Redis 集群重新分片
重新分片意味着一些哈希槽会从一个节点迁移到其他节点，可以使用命令行实现
```shell
redis-cli --cluster reshard <host>:<port> \
--cluster-from <node-id> --cluster-to <node-id>
--cluster-slots <number of slots> --cluster-yes
```
### 添加新结点
添加新节点基本上就是添加空节点然后将一些数据移入其中(如果是主节点)或者设置为已知节点的副本(如果是从节点)的过程。
#### 添加主节点
- 创建新节点，和创建集群一样创建新的节点
- 使用命令行工具向集群中添加新的节点
  ```shell
  -- 第一个参数为新加入集群的节点，第二个参数为集群中任意一个节点
  redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000
  ```
- 连接新节点查看是否加入集群
  ```shell
  cluster nodes
  ```
由于新节点已经加入了集群，因此它能够正确的重定向客户端的查询，并且已经成为集群的一部分；但是和其他主节点相比，它有几个特征：
- 没有数据，因为它没有分配哈希槽
- 因为是没有分配哈希槽的主节点，所以当从节点切换为主节点时它不参与选举过程
可以使用重新分片功能为此节点分配哈希槽
#### 添加从节点
添加从节点和添加主节点只是在 redis-cli 的参数上有所不同
```shell
-- 指定为随机一个主节点的从节点
redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave

-- 指定为特定主节点的从节点
redis-cli --cluster add-node 127.0.0.1:7006 127.0.0.1:7000 --cluster-slave --cluster-master-id 3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e
```
### 移除节点
移除节点直接使用命令行工具：
```shell
-- 第一个参数为集群任意节点，第二个参数是删除节点的 id
redis-cli --cluster del-node 127.0.0.1:7000 <node-id>
```
这种方式也可以用于删除主节点，但是主节点在删除之前必须是空的，否则需要将数据重新分片到其他主节点；也可以在一个从节点上执行手动故障转移并在节点从主节点变为从节点后将其删除。
### 迁移从节点
使用命令行工具可以随时迁移一个从节点到另一个主节点：
```shell
cluster replicas <master-node-id>
```
在某些情况下，从节点可以自动迁移到主节点下能够提升 Redis 集群的稳定性。当一个主节点的从节点故障时，多个从节点中的一个就会迁移到这个主节点下，这样即使主节点发生故障也能通过选举从节点来继续提供服务。
- 集群会尝试从拥有最多从节点的主节点下迁移从节点
- 从节点迁移是自动的，因此在向集群中添加节点的时候随机指定从节点的主节点就行
- redis.conf 中的 cluster-migration-barrier 可以控制副本的迁移

## Redis 集群实现细节
### Redis 集群协议
在 Redis 集群中，节点负责保存数据并获取集群的状态，包括将 key 映射到正确的节点。集群节点还能够自动发现其他节点，检测非工作节点，并在需要的时候将从节点提升为主节点，以便在发生故障的时候能够继续运行。

集群中所有的节点使用 TCP 和二进制的协议(Redis 集群总线)互相连接，节点之前使用 gossip 协议传播集群的信息以便发现新的节点，发送 ping 数据包确保其他节点工作正常以及发送集群特定条件下的信号；集群总线还用于在集群间传播 pub/sub 消息。

Redis 集群没有代理，因此使用重定向错误 -MOVED 和 -ASK 将客户端的请求重定向到其他节点；理论上，Redis 客户端可以自由的向集群中所有的节点发送请求并在需要的时候重定向，因此客户端不需要保存集群的状态，但是如果客户端能够缓存 key 和集群节点的映射关系，那么可以提升查询性能。
### 写安全
Redis 集群使用异步复制，这就意味着当从节点被选举为主节点之后，该节点的数据将会覆盖其他节点的数据。总会有一个时间窗口可以看到写数据丢失，但是这个时间窗口在客户端连接大部分主节点的分区还是少数主节点的分区是有很大区别。
Reids 集群会丢失数据的情况：
- 写操作到达主节点后，主节点回复客户端，但是此时如果主节点还没有将数据异步复制到从节点上就发生故障，那么从节点选举为主节点之后这段时间内的数据将会丢失；但是这种情况很难观察到，因为主节点在回复客户端和异步复制数据到从节点几乎是同时发生。
- 另外一种可能丢数据的情况在网络发生分区时：
  - 由于网络分区，主节点无法访问
  - 从节点被选举为主节点
  - 网络恢复，客户端在旧主节点转换为从节点之前将数据写入
第二种故障模式不太可能发生，因为主节点不能和集群中的大多数主节点通信一定时间后将会拒绝写入；当网络分区修复需要一定时间用于其他节点通知配置更改，这段时间内也是拒绝写入的；而且次故障还要求客户端的路由表还没有更新

针对节点数比较少的分区这个时间窗口就会更大，例如：至少一个客户端连接上了 Redis 集群中较少节点的分区，那么在节点较多的分区发生故障转移之后，客户端之前写入的数据将会全部丢失。

具体来说，对于需要进行故障转移的主节点来说，必须要集群中的大多数节点在 NODE_TIMEOUT 时间内访问不到才会进行故障转移。因此如果在该时间内网络分区问题修复则不会有任何数据丢失，当网络分区超过 NODE_TIMEOUT，则节点较少的分区的所有写操作肯能会丢失；但是一旦超过 NODE_TIMEOUT 时间后节点较少的分区不能和节点较多的分区通信节点较少的分区将会不可用而拒绝写入，因此数据丢失的窗口有一个最大值

### 集群属性
Redis 集群中每个节点都有一个唯一的名称，节点名称是160位随机数的十六进制表示，在第一次启动节点时获得。节点将这个 ID 存储在配置文件中，只要配置文件没有删除或者强制使用 ```cluster reset``` 命令，这个 ID 一直不会变

节点 ID 用于标识整个集群中的每个节点，即使节点的 IP 更改了也无需更改节点 ID

每个节点维护着集群中其他节点的信息，使用 ```cluster nodes``` 命令可以查看集群中所有的节点信息：
```shell
<id> <ip:port> <flags> <master> <ping-sent> <pong-recv> <config-epoch> <link-state> <slot>-<slot> ... <slot>
```
- ```id```：节点 ID，由 40 字符组成的随机字符串并且不会被改变(除非使用 cluster reset hard 命令)
- ```ip:port@cport```：节点提供给客户端查询的 IP 和端口
- ```flags```：一组标识
  - ```myself```：通信的节点
  - ```master/slave```：当前节点为 master 或者 replica
  - ```fail?/fail```：结点状态为 PFAIL(疑似下线)或者 FAIL(下线)
  - ```handshake/noaddr```：节点进行握手的/节点不为其他节点感知
  - ```noflags```：没有 flags
- ```master```：如果当前节点是副本并且存在 master，则是 master 的 ID，否则是 "-"
- ```ping-sent/pong-recv```：节点上次发送 ping 到现在的时间/上次收到 pong 到现在的时间
- ```config-epoch```：master 节点的 config-epoch，每次 master 失效就会创建一个新的、单调递增的 config-epoch
- ```linke-state```：节点到节点的连接状态，可以为 "connected" 和 "disconnected" 两种状态
- ```slot```：哈希槽的范围，用 ```start-end``` 表示这个范围包含 start 和 end 之间的哈希槽由当前节点处理

### 集群拓扑
Redis 集群是一个完整的网络，其中每个节点使用TCP连接与每个其他节点连接；在N个节点的集群中，每个节点具有N-1个传出TCP连接和N-1个传入连接，这些TCP连接始终保持活动状态，不按需创建。当节点期望在响应集群总线中的ping时发出pong应答时，在等待足够长的时间以将节点标记为不可达之前，它将尝试通过从头开始重新连接来刷新与节点的连接。当Redis Cluster节点形成一个完整的网格时，节点使用 gossip 协议和配置更新机制，以避免在正常情况下在节点之间交换太多消息，因此交换的消息数量不是指数级的。
### 节点握手
节点始终接受群集总线端口上的连接，甚至即使ping节点不受信任也会回复收到的 ping。但是，如果发送节点不被视为群集的一部分，则接收节点将丢弃所有数据包。

节点以两中方式接受一个节点作为集群的一部分：
- 节点发送 MEET 信息来表名自己；MEET 信息和 ping 信息完全相同，但是强制接收者接受发送消息的节点作为集群的一部分；当且仅当系统管理员使用 ```cluster meet <ip> <port>``` 命令时节点才会发出 meet 消息到其他节点将该结点加入到当前节点的集群
- 已经信任的节点向其他节点告知新的节点，那么这个节点将会被注册为集群的一部分。即如果 A 知道 B，并且 B 知道 C，B 向 A 发送 C 的信息，则 A 就会将 C 注册为集群的一部分并尝试与 C 连接。因此只需要使新加入的节点连接上集群中的任意一个节点，它们将最终自动的形成完全连接的图；这意味着集群能够自动发现其他节点，前提是系统管理员建立了信任关系

### 槽指派
Redis 通过分片的方式来保存数据库中的键值对；集群的整个数据库被分为 16384 个槽，数据库中的每个键都属于这 16384 个槽的其中一个，集群中的每个节点可以处理 0-16384 个键。

当数据库中的 16384 个槽都有节点在处理时，集群处于上线状态，否则即使有一个槽没有得到处理整个集群也处于下线状态。

指定节点负责的槽有 4 个相关命令：
- ```cluster addslots <slot1> [slot2 ... slotN]```：直接指定节点负责的槽，一般在集群刚创建时使用
- ```cluster delslots <slot1> [slot2 ... slotN]```：移除节点负责的槽，用于手动修改集群的分片配置，一般很少使用
- ```cluster setslot <slot> NODE <node>```：指定一个槽到指定的节点
- ```cluster setslot <slot> MIGRATING <node>```：将当前槽设置为 MIGRATING 状态，当前节点接收所有关于这个槽的查询，只有当查询的 key 存在时返回否则返回 ASK 错误重定向到新的迁移目标 node 上
- ```cluster setslot <slot> IMPORTING <node>```：将当前槽设置为 IMPORTING 状态，当前节点接收所有关于这个槽的查询，只有查询已经被 ASKING 命令处理过才会处理，否则返回 MOVED 错误重定向到该槽的原始节点处理

Redis 集群单个槽 slot 进行重分片的步骤：
- 对目标节点发送 ```cluster setslot <slot> importing <source_node_id>``` 命令让目标节点准备好从源节点导入属于槽 slot 的键值对
- 对源节点发送 ```cluster setslot <slot> migrating <target_node_id>``` 命令让源节点准备好将属于槽 slot 的键值对迁移到目标节点
- 向源节点发送 ```cluster getkeysinslot <slot> <count>``` 命令获取最多 count 个属于槽 slot 的键值对的键名
- 对于每个获取到的键名，向源节点发送 ```migrate <target_node_ip> <target_node_port> <key_name> 0 <timeout>``` 命令将键原子的从源节点迁移到目标节点
- 重复执行获取键和迁移键的操作，直到所有属于槽 slot 的键值对全部迁移到目标节点
- 向集群中的所有节点发送 ```cluster setslot <slot> NODE <target_id>``` 命令将槽指派给目标节点

### MOVED 重定向
Redis 客户端可以自由的向集群中的任意节点发送查询，包括从节点；节点分析查询，如果是可接受的(单个 key 或者多个 key 是相同的 hash 槽)则会查找负责该 hash 槽的节点，如果该节点负责处理处理 hash 槽则直接处理返回结果，否则在节点内部查找负责 hash 槽的节点，返回 MOVE 错误给客户端。

MOVE 错误包括 key 对应的 hash 槽和提供查询的节点的 ip 和 port，客户端需要重新查询新的节点，如果在此期间集群发生变更导致 hash 槽变化，则依然会再次返回 MOVE 错误
### ASK 重定向
在进行重分片期间，源节点向目标节点迁移一个槽的过程中可能会出现一种情况：属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对保存在目标节点里面。

当客户端向源节点发送一个命令需要处理的键恰好属于正在被迁移的槽时：
- 如果源节点能在自己的数据库中查找到指定的键，则直接执行客户端发送的命令
- 如果源节点不能再自己的数据库中查找到指定的键，则向客户端返回 ASK 错误并重定向到正在迁移的槽的目标节点

接收到 ASK 错误的客户端会根据错误提供的 IP 地址和端口转向至正在导入槽的目标节点，然后首先向目标节点发送 ASKING 命令，然后再重新发送原本想要执行的命令。如果没有发送 ASKING 命令而直接发送需要指定的命令，目标节点会拒绝执行并返回 MOVED 错误。

ASK 错误和 MOVED 错误的区别：
- MOVED 错误代表槽的负责权已经从一个结点转移到了另一个节点；客户端收到关于槽 slot 的 MOVED 错误之后所有关于 slot 槽的命令都可以直接发送到 MOVED 错误指定的节点
- ASK 错误只是两个节点在迁移槽的过程中使用，当客户端收到关于槽 slot 的 ASK 错误后只有接下来的一次请求会发送到 ASK 错误指定的节点，后续的操作还是会请求到源节点
### 失效检测
集群中的每个节点都会定期向集群中的其他节点发送 PING 消息，如果接收 PING 消息的节点没有在规定的时间内返回 PONG 消息，那么发送 PING 消息的节点就会将接收 PING 消息的节点标记为疑似下线(probable fail, PFAIL)。

集群中的各个节点会通过互相发送消息交换集群中各个节点的状态信息，如果一个集群中半数以上负责处理槽的主节点都将某个主节点 x 报告为疑似下线，那么这个主节点 x 将被标记为以下线(FAIL)，将主节点 x 标记为已下线的节点会向集群广播关于节点 x 的 FAIL 消息，所有接收到这条消息的节点(包括 replica 节点)会立即将主节点 x 标记为下线

### 故障转移
当一个 replica 节点发现自己的 master 节点进入已下线状态就会开始对下线的 master 节点进行故障转移：
- 从 replica 集合中选取一个结点
- 被选中的节点执行 ```slaveof no one``` 命令成为新的主节点
- 新的主节点将旧的主节点的槽指派给自己
- 新的主节点向集群广播一条 PONG 消息告知其他节点主节点的变更
- 新的主节点开始接收和处理负责的槽相关的请求命令，故障转移完成

新的主节点的选举过程：
- 集群的 config-epoch 是一个自增计数器，初始值为 0
- 当集群的某个结点开始一次故障转移时，config-epoch 的值会加 1
- 对于每个 config-epoch 集群里每个负责处理槽的主节点都有一次投票的机会，第一个向主节点要求投票的从节点将获得主节点的投票
- 当从节点发现自己的 master 节点进行下线状态时会立即向集群中广播一条 ```CLUSTERMSG_TYPE_FAILOVER_AUTH_REQUEST``` 消息，要求所有接收到这条消息且具有投票权的主节点向这个从节点投票
- 如果一个主节点具有投票权并且这个主节点尚未投票给其他从节点，那么该主节点就会向要求投票的从节点返回一条 ```CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK``` 消息表示主节点支持该从节点成为新的主节点
- 每个参与选举的从节点都会接收 ```CLUSTERMSG_TYPE_FAILOVER_AUTH_ACK``` 消息并根据自己接收到了多少条这种消息来统计自己获得了多少主节点的支持
- 如果集群里有 N 个具有投票权的主节点，那么当一个从节点收集到大于等于 N/2+1 个投票时，这个从节点就会当选为新的主节点
- 如果在一个 config-epoch 里面没有从节点能收集到足够多的投票，那么集群会进入下一个新的 config-epoch 并再次进行选举直到选举出新的主节点为止

**[Back](../)**